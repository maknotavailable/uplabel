{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unified UpLabel Pipeline\n",
    "\n",
    "Testing ground for unified labeling pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import configparser\n",
    "import sys\n",
    "\n",
    "sys.path.append('../code')\n",
    "import main\n",
    "import utils as ut\n",
    "import complexity as cp\n",
    "import split as sp\n",
    "import join as jo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../config.ini']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read('../config.ini', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = config['path']['data']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input \n",
    "Parameters & Upload.\n",
    "- File (Raw Data + expert labelled)\n",
    "- Column names\n",
    "- Extra columns (to be ingored in processing, but output)\n",
    "- Target column\n",
    "- Language\n",
    "- Task Type\n",
    "- N# labelers (0..*)\n",
    "- Quality: strict/easy (strict considers tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['label', 'text', 'tag'], dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(data_dir+'lab/input.txt', sep='\\t', encoding='utf-8')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data\n",
    "\n",
    "- Unified format\n",
    "- remove duplicates\n",
    "- Warning message for unknown items\n",
    "- handle tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] **** ITERATION # 0 ****\n",
      "[INFO] Input Length -> 9245\n",
      "[INFO] Label Summary: \n",
      "Web              77\n",
      "Panorama         73\n",
      "International    68\n",
      "Sport            64\n",
      "Wirtschaft       63\n",
      "Inland           47\n",
      "Etat             42\n",
      "Wissenschaft     40\n",
      "Kultur           26\n",
      "Name: label, dtype: int64\n",
      "[INFO] Post Duplicate Length -> 9244\n",
      "\n",
      "[INFO] Estimating complexity using SUPERVISED approach.\n",
      "\t[INFO] Data available for training -> 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\uplab\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[INFO] Complexity Estimation Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.73      0.73        15\n",
      "           1       0.67      0.71      0.69        14\n",
      "           2       0.73      0.62      0.67        13\n",
      "           3       0.71      1.00      0.83        12\n",
      "           4       0.88      0.58      0.70        12\n",
      "           5       0.86      0.67      0.75         9\n",
      "           6       1.00      0.62      0.77         8\n",
      "           7       0.58      0.88      0.70         8\n",
      "           8       0.67      0.80      0.73         5\n",
      "\n",
      "   micro avg       0.73      0.73      0.73        96\n",
      "   macro avg       0.76      0.73      0.73        96\n",
      "weighted avg       0.75      0.73      0.73        96\n",
      "\n",
      "\t[INFO] Complexity Score -> 0.7270112849315437\n",
      "\n",
      "[INFO] Applying model to data\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "ul = main.Main('lab', debug_iter_id=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "ul = main.Main('tal', debug_iter_id=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] **** ITERATION # 1 ****\n",
      "[INFO] Loading splits from iteration 0.\n",
      "\t[INFO] Quality Score of Labeler 1 -> 0.0625\n",
      "\t[INFO] Quality Score of Labeler 2 -> 0.0\n",
      "[INFO] Input Length -> 3806\n",
      "[INFO] Label Summary: \n",
      "documentDate       802\n",
      "damageDate          92\n",
      "gracePeriodDate     67\n",
      "None                24\n",
      "Name: label, dtype: int64\n",
      "[INFO] Post Duplicate Length -> 3806\n",
      "\n",
      "[INFO] Estimating complexity using SUPERVISED approach.\n",
      "\t[INFO] Data available for training -> 3806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\uplab\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[INFO] Complexity Estimation Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.98      0.85       564\n",
      "           1       0.31      0.03      0.05       160\n",
      "           2       0.00      0.00      0.00        18\n",
      "           3       0.00      0.00      0.00        13\n",
      "           4       0.00      0.00      0.00         4\n",
      "\n",
      "   micro avg       0.74      0.74      0.74       759\n",
      "   macro avg       0.21      0.20      0.18       759\n",
      "weighted avg       0.62      0.74      0.64       759\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\uplab\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[INFO] Complexity Score -> 0.6387290247664161\n",
      "\n",
      "[INFO] Applying model to data\n",
      "[INFO] Storing split: C:/Users/makayser/Desktop/ul_local/tal/input-it_1-split_1.xlsx\n",
      "    262\n",
      "Name: pred, dtype: int64\n",
      "[INFO] Storing split: C:/Users/makayser/Desktop/ul_local/tal/input-it_1-split_2.xlsx\n",
      "                240\n",
      "documentDate      2\n",
      "Name: pred, dtype: int64\n",
      "Wall time: 5.76 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "ul = main.Main('tal', debug_iter_id=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] **** ITERATION # 1 ****\n",
      "[INFO] Loading splits from iteration 0.\n",
      "\t[INFO] Quality Score of Labeler 1 -> 0.0625\n",
      "\t[INFO] Quality Score of Labeler 2 -> 0.0\n",
      "[INFO] Input Length -> 3806\n",
      "[INFO] Label Summary: \n",
      "documentDate       802\n",
      "damageDate          92\n",
      "gracePeriodDate     67\n",
      "None                24\n",
      "Name: label, dtype: int64\n",
      "[INFO] Post Duplicate Length -> 3806\n",
      "\n",
      "[INFO] Estimating complexity using SUPERVISED approach.\n",
      "\t[INFO] Data available for training -> 3806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\uplab\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[INFO] Complexity Estimation Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.88      0.82       564\n",
      "           1       0.40      0.25      0.31       160\n",
      "           2       0.75      0.17      0.27        18\n",
      "           3       0.38      0.23      0.29        13\n",
      "           4       0.50      0.25      0.33         4\n",
      "\n",
      "   micro avg       0.72      0.72      0.72       759\n",
      "   macro avg       0.56      0.36      0.40       759\n",
      "weighted avg       0.68      0.72      0.69       759\n",
      "\n",
      "\t[INFO] Complexity Score -> 0.690406749802699\n",
      "\n",
      "[INFO] Applying model to data\n",
      "[[0.9361741  0.0638259  0.         0.         0.        ]\n",
      " [0.60835684 0.39164316 0.         0.         0.        ]\n",
      " [0.60835684 0.39164316 0.         0.         0.        ]\n",
      " ...\n",
      " [0.9361741  0.0638259  0.         0.         0.        ]\n",
      " [0.9361741  0.0638259  0.         0.         0.        ]\n",
      " [0.9361741  0.0638259  0.         0.         0.        ]]\n",
      "[[ 0.32781726 -0.32781726  0.          0.          0.        ]\n",
      " [-0.17501858  0.17501858  0.          0.          0.        ]\n",
      " [-0.17501858  0.17501858  0.          0.          0.        ]\n",
      " ...\n",
      " [ 0.32781726 -0.32781726  0.          0.          0.        ]\n",
      " [ 0.32781726 -0.32781726  0.          0.          0.        ]\n",
      " [ 0.32781726 -0.32781726  0.          0.          0.        ]]\n",
      "(3806, 5)\n",
      "[INFO] Storing split: C:/Users/makayser/Desktop/ul_local/tal/input-it_1-split_1.xlsx\n",
      "                   191\n",
      "documentDate         4\n",
      "gracePeriodDate      1\n",
      "Name: pred, dtype: int64\n",
      "[INFO] Storing split: C:/Users/makayser/Desktop/ul_local/tal/input-it_1-split_2.xlsx\n",
      "                   181\n",
      "documentDate         4\n",
      "gracePeriodDate      1\n",
      "Name: pred, dtype: int64\n",
      "Wall time: 3.62 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "ul = main.Main('tal', debug_iter_id=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1, 2, 3]\n",
    "b = [3, 2, 1]\n",
    "c = np.array([a, b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 3])"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0.],\n",
       "       [3., 3., 3.],\n",
       "       [6., 6., 6.]])"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = np.arange(9.0).reshape((3, 3))\n",
    "x2 = np.arange(3.0)\n",
    "np.subtract(x1, x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 2.])"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1  1]\n"
     ]
    }
   ],
   "source": [
    "print(c[:,0] -c[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimate Complexity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Not enough examples for label ('documentDate', 5)\n",
      "[INFO] Estimating complexity.\n",
      "[INFO] Data available for training -> 74\n",
      "[INFO] Complexity Estimation Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80         5\n",
      "           1       1.00      0.75      0.86         4\n",
      "           2       0.67      0.67      0.67         3\n",
      "           3       0.00      0.00      0.00         1\n",
      "\n",
      "   micro avg       0.69      0.69      0.69        13\n",
      "   macro avg       0.62      0.55      0.58        13\n",
      "weighted avg       0.77      0.69      0.73        13\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6923076923076923"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cp.run(df_data, estimate_clusters=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster\n",
    "Only applies if complexity calculation not sufficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine Split\n",
    "Overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 0.27)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.calculate_split(3806, 0.73, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splits = sp.apply_split(df_all, '../raw.txt', complexity=0.6, labelers=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Split\n",
    "- Split (x exports)\n",
    "- Include extra columns\n",
    "- Include label columns: scored, label, comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "\t[INFO] Quality Score of Labeler 1 -> 0.0625\n",
      "16\n",
      "\t[INFO] Quality Score of Labeler 2 -> 0.0\n"
     ]
    }
   ],
   "source": [
    "t1, t2, t3 = jo.load_splits(data_dir + 'tal/', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tc = jo.join_splits(t1, t2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Instructions\n",
    "\n",
    "- Labels:  \n",
    "-- as defined   \n",
    "-- None is 'None'  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (uplabel)",
   "language": "python",
   "name": "uplab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
